{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPSkBppBlCpOppWvQtpwIj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IVPITER080306/Dash_Lab_repository_f20241403/blob/main/Naive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pjgTjtaSEzVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "447d7b7e-6c1c-4d75-81d7-3f1e86def668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing naive.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile naive.cu\n",
        "#include <stdio.h>\n",
        "#include<cuda_runtime.h>\n",
        "#include <stdlib.h> // for rand()\n",
        "\n",
        "__global__ void naivemult(float *a, float *b, float *c, int m, int k, int n)\n",
        "{\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x; // column index\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y; // row index\n",
        "    if (row < m && col < n) {\n",
        "        float sum = 0.0f;\n",
        "        for (int i = 0; i < k; i++) {\n",
        "            sum += a[row * k + i] * b[i * n + col]; // multply (dot product) & accumulate\n",
        "        }\n",
        "        c[row * n + col] = sum; // store result\n",
        "    }\n",
        "}\n",
        "void init_matrix(float *mat, int rows, int cols) {\n",
        "    for (int i = 0; i < rows * cols; i++) {\n",
        "        mat[i] = (float)rand() / RAND_MAX; // generate random float between 0 and 1\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int  main()\n",
        "{\n",
        "    const int M = 1024;\n",
        "    const int K = 1024;  // dimensions for matrix A(MxK) and B(KxN)\n",
        "    const int N = 1024;\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start); //initializing cuda event objects\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    //initialize host pointers\n",
        "    float *h_a, *h_b, *h_c_gpu;\n",
        "    //initialize device pointers\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    // initialize sizes\n",
        "    size_t size_a = M * K * sizeof(float);\n",
        "    size_t size_b = K * N * sizeof(float);\n",
        "    size_t size_c = M * N * sizeof(float);\n",
        "    // allocate host memory\n",
        "    h_a = (float *)malloc(size_a);\n",
        "    h_b = (float *)malloc(size_b);\n",
        "    h_c_gpu = (float *)malloc(size_c);\n",
        "    // initialize matrices\n",
        "    init_matrix(h_a, M, K);\n",
        "    init_matrix(h_b, K, N);\n",
        "    // allocate device memory\n",
        "    cudaMalloc((void **)&d_a, size_a);\n",
        "    cudaMalloc((void **)&d_b, size_b);\n",
        "    cudaMalloc((void **)&d_c, size_c);\n",
        "    // copy matrices from host to device\n",
        "    cudaMemcpy(d_a, h_a, size_a, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size_b, cudaMemcpyHostToDevice);\n",
        "    // initialize grid and block dimensions\n",
        "    dim3 block(16, 16);\n",
        "    dim3 grid((N + block.x - 1) / block.x, (M + block.y - 1) / block.y); // ceiling division\n",
        "    // execute kernel\n",
        "    naivemult<<<grid, block>>>(d_a, d_b, d_c, M, N, K);\n",
        "    //synchronize device\n",
        "    cudaDeviceSynchronize();\n",
        "    // Timed Benchmarking\n",
        "    int iterations = 100;\n",
        "    float total_time = 0.0f;\n",
        "\n",
        "    for (int i = 0; i < iterations; i++) {\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "\n",
        "\n",
        "        naivemult<<<grid, block>>>(d_a, d_b, d_c, M, N, K);\n",
        "\n",
        "\n",
        "        cudaEventRecord(stop);\n",
        "\n",
        "\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "\n",
        "        float iter_time;\n",
        "        cudaEventElapsedTime(&iter_time, start, stop);\n",
        "        total_time += iter_time;\n",
        "    }\n",
        "    printf(\"Average kernel execution time: %f ms\\n\", total_time / iterations);\n",
        "    // copy result matrix from device to host\n",
        "    cudaMemcpy(h_c_gpu, d_c, size_c, cudaMemcpyDeviceToHost);\n",
        "    // destroy cuda event objects\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    // free device memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    // free host memory\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c_gpu);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 naive.cu -o naive\n",
        "!./naive"
      ],
      "metadata": {
        "id": "kKyjg04g-C60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b9148a-a3e8-40e0-eb35-d63f1bddb166"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average kernel execution time: 5.444615 ms\n"
          ]
        }
      ]
    }
  ]
}